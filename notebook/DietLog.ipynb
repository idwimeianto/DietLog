{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DietLog_v1_3_classes_edit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import"
      ],
      "metadata": {
        "id": "4zkJE8EDo_f_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5MttDH1mlUY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "import os\n",
        "import random\n",
        "import collections\n",
        "from collections import defaultdict\n",
        "\n",
        "import shutil\n",
        "from shutil import copy\n",
        "from shutil import copytree, rmtree\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download Datasets"
      ],
      "metadata": {
        "id": "6Z2Q7GJppSqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_and_extract():\n",
        "  if \"food-101\" in os.listdir():\n",
        "    print(\"Dataset already exists\")\n",
        "  else:\n",
        "    tf.keras.utils.get_file(\n",
        "      'food-101.tar.gz',\n",
        "      'http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz',\n",
        "      cache_subdir='/content',\n",
        "      extract=True,\n",
        "      archive_format='tar',\n",
        "      cache_dir=None\n",
        "    )"
      ],
      "metadata": {
        "id": "4FqIRu5-nWee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_dataset_and_extract()"
      ],
      "metadata": {
        "id": "MuXpnzpHoiun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspect the Dataset Structure"
      ],
      "metadata": {
        "id": "ITJH0E5ntGBP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Folder Structure and Files"
      ],
      "metadata": {
        "id": "v97rSx3lhrif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_path = 'food-101/'"
      ],
      "metadata": {
        "id": "g1Xos1oOh9Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(main_path)"
      ],
      "metadata": {
        "id": "UaqcAaHfqev5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(os.path.join(main_path, 'images'))"
      ],
      "metadata": {
        "id": "Yj77blCgqg2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(os.path.join(main_path, 'meta'))"
      ],
      "metadata": {
        "id": "84hv4Z7_qi2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_files = os.path.join(main_path, 'meta/classes.txt')\n",
        "\n",
        "classes = []\n",
        "with open(classes_files, 'r') as txt:\n",
        "    classes = [read.strip() for read in txt.readlines()]\n",
        "\n",
        "classes"
      ],
      "metadata": {
        "id": "gWifL_Qti1mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_files = os.path.join(main_path, 'meta/labels.txt')\n",
        "\n",
        "labels = []\n",
        "with open(labels_files, 'r') as txt:\n",
        "    labels = [read.strip() for read in txt.readlines()]\n",
        "\n",
        "labels"
      ],
      "metadata": {
        "id": "60JRkvhZhu6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualize image"
      ],
      "metadata": {
        "id": "E0qPYyAxtObe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "pic_index = 0 # Index for iterating over images\n",
        "\n",
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "print(classes)\n",
        "\n",
        "rdm_classes = random.sample(classes, len(classes))[:4]     \n",
        "\n",
        "pic_index+=4\n",
        "\n",
        "rdm_classes_img = []\n",
        "for class_item in rdm_classes: \n",
        "  class_img = [os.path.join(main_path+'/images/'+class_item, fname) \n",
        "                      for fname in os.listdir(main_path+'/images/'+class_item)[pic_index-4:pic_index]\n",
        "                    ]\n",
        "  rdm_classes_img.extend(class_img)\n",
        "\n",
        "for i, img_path in enumerate(rdm_classes_img):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XVsXM33LTX-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split the image data into train and validation using train.txt and test.txt"
      ],
      "metadata": {
        "id": "shS5RxwytVL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(filepath, src, dir):\n",
        "  images_files = defaultdict(list)\n",
        "  with open(filepath, 'r') as txt:\n",
        "      paths = [read.strip() for read in txt.readlines()]\n",
        "      for p in paths:\n",
        "        images_path = p.split('/')\n",
        "        images_files[images_path[0]].append(images_path[1] + '.jpg')\n",
        "\n",
        "  for food in images_files.keys():\n",
        "    if not os.path.exists(os.path.join(dir,food)):\n",
        "      os.makedirs(os.path.join(dir,food))\n",
        "    for i in images_files[food]:\n",
        "      copy(os.path.join(src,food,i), os.path.join(dir,food,i))"
      ],
      "metadata": {
        "id": "MsDMiBqhsei7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = main_path+'datasets/train'\n",
        "validation_dir = main_path+'datasets/validation'"
      ],
      "metadata": {
        "id": "Kylr8CKMwd-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare train dataset\n",
        "split_dataset(main_path+'meta/train.txt', main_path+'images', train_dir)"
      ],
      "metadata": {
        "id": "IbTbBPyut1z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare validation dataset\n",
        "split_dataset(main_path+'meta/test.txt', main_path+'images', validation_dir)"
      ],
      "metadata": {
        "id": "qCfOwo04t4BU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many files are in the train folder\n",
        "train_files = sum([len(files) for i, j, files in os.walk(train_dir)])\n",
        "print(\"Total number of files in train folder\")\n",
        "print(train_files)"
      ],
      "metadata": {
        "id": "xtjdwxw3t6FS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many files are in the test folder\n",
        "validation_files = sum([len(files) for i, j, files in os.walk(validation_dir)])\n",
        "print(\"Total number of files in validation folder\")\n",
        "print(validation_files)"
      ],
      "metadata": {
        "id": "V8NFJN2Ct7Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training and Validation Generators"
      ],
      "metadata": {
        "id": "aQEE5d7NuZc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_generator(train_dir, validation_dir, batch_size, img_width, img_height):\n",
        "  train_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255.,\n",
        "      rotation_range = 40,\n",
        "      width_shift_range = 0.2,\n",
        "      height_shift_range = 0.2,\n",
        "      shear_range = 0.2,\n",
        "      zoom_range = 0.2,\n",
        "      horizontal_flip = True)\n",
        "\n",
        "  validation_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        "  )\n",
        "\n",
        "  validation_generator = validation_datagen.flow_from_directory(\n",
        "      validation_dir,\n",
        "      target_size=(img_height, img_width),\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical')\n",
        "  \n",
        "  return train_generator, validation_generator\n"
      ],
      "metadata": {
        "id": "7Quv52l0GcrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "img_width = 300\n",
        "img_height = 300"
      ],
      "metadata": {
        "id": "K8BZooenQM9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator, validation_generator = train_val_generator(train_dir, validation_dir, batch_size, img_width, img_height)"
      ],
      "metadata": {
        "id": "yIFtIGxyPBN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Model"
      ],
      "metadata": {
        "id": "PRb-635QyVmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "metadata": {
        "id": "WlkDdxHBRE3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'"
      ],
      "metadata": {
        "id": "9n7JGAjYRFma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pre_trained_model(local_weights_file, img_width, img_height):\n",
        "  pre_trained_model = InceptionV3(input_shape = (img_width, img_height, 3),\n",
        "                                  include_top = False, \n",
        "                                  weights = None) \n",
        "\n",
        "  pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "  # Make all the layers in the pre-trained model non-trainable\n",
        "  for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  return pre_trained_model"
      ],
      "metadata": {
        "id": "aJU1waNKRJ-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model = create_pre_trained_model(local_weights_file, img_width, img_height)\n",
        "\n",
        "# Print the model summary\n",
        "pre_trained_model.summary()"
      ],
      "metadata": {
        "id": "nRB7LDV0TGG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = pre_trained_model.count_params()\n",
        "num_trainable_params = sum([w.shape.num_elements() for w in pre_trained_model.trainable_weights])\n",
        "\n",
        "print(f\"There are {total_params:,} total parameters in this model.\")\n",
        "print(f\"There are {num_trainable_params:,} trainable parameters in this model.\")"
      ],
      "metadata": {
        "id": "goVuAqn0TK1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output_of_last_layer(pre_trained_model):\n",
        "  last_desired_layer = pre_trained_model.get_layer('mixed7')\n",
        "  print('last layer output shape: ', last_desired_layer.output_shape)\n",
        "  last_output = last_desired_layer.output\n",
        "  print('last layer output: ', last_output)\n",
        "\n",
        "  return last_output"
      ],
      "metadata": {
        "id": "JdxbdBw2Tioz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_output = output_of_last_layer(pre_trained_model)"
      ],
      "metadata": {
        "id": "KdV2fLzaTqf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(labels)\n",
        "num_classes"
      ],
      "metadata": {
        "id": "lo62wwarVoc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(pre_trained_model, last_output, num_classes):\n",
        "  # Flatten the output layer to 1 dimension\n",
        "  x = layers.Flatten()(last_output)\n",
        "\n",
        "  # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
        "  x = layers.Dense(512, activation='relu')(x)\n",
        "  # Add a dropout rate of 0.2\n",
        "  x = layers.Dropout(0.2)(x)  \n",
        "  # Add a final softmax layer for classification\n",
        "  x = layers.Dense(num_classes, activation='softmax')(x)        \n",
        "\n",
        "  # Create the complete model by using the Model class\n",
        "  model = Model(inputs=pre_trained_model.input, outputs=x)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer = SGD(learning_rate=0.0001), \n",
        "                loss = 'categorical_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "a9UMIThMT9_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save your model in a variable\n",
        "model = create_model(pre_trained_model, last_output, num_classes)\n",
        "\n",
        "# Inspect parameters\n",
        "total_params = model.count_params()\n",
        "num_trainable_params = sum([w.shape.num_elements() for w in model.trainable_weights])\n",
        "\n",
        "print(f\"There are {total_params:,} total parameters in this model.\")\n",
        "print(f\"There are {num_trainable_params:,} trainable parameters in this model.\")"
      ],
      "metadata": {
        "id": "Ju5tbA9zVg5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Model"
      ],
      "metadata": {
        "id": "2AAsrIrn5lvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "EbVOhaEB5pW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(num_epochs):\n",
        "  checkpoint_path = \"training_1/cp.ckpt\"\n",
        "  checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "  # Create a callback that saves the model's weights\n",
        "  cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                  save_weights_only=True,\n",
        "                                                  verbose=1)\n",
        "\n",
        "  history = model.fit(train_generator,\n",
        "                      steps_per_epoch=train_files // batch_size, \n",
        "                      validation_data=validation_generator,\n",
        "                      validation_steps=train_files // batch_size,\n",
        "                      epochs=num_epochs,\n",
        "                      verbose=1,\n",
        "                      callbacks=[cp_callback])\n",
        "  return history"
      ],
      "metadata": {
        "id": "R6a_wHjOVx5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(num_epochs)"
      ],
      "metadata": {
        "id": "hUHs_xpIcL7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize the accuracy and loss plots"
      ],
      "metadata": {
        "id": "y9oXBBmLcUpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracy(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_loss(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_accuracy(history,'Model Accuracy')\n",
        "plot_loss(history,'Model Loss')"
      ],
      "metadata": {
        "id": "X0Z6S0TxcR3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predicting"
      ],
      "metadata": {
        "id": "3lByEE3Fdo85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_class(model, images):\n",
        "  for img in images:\n",
        "    img = image.load_img(img, target_size=(img_width, img_height))\n",
        "    x = image.img_to_array(img)                    \n",
        "    x = np.expand_dims(img, axis=0)\n",
        "\n",
        "    images = np.vstack([x])\n",
        "    images = images / 255.                                   \n",
        "\n",
        "    pred = model.predict(images)\n",
        "    index = np.argmax(pred)\n",
        "    pred_value = labels[index]\n",
        "    print(pred)\n",
        "\n",
        "    plt.imshow(img)                           \n",
        "    plt.axis('off')\n",
        "    plt.title(pred_value)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XD0B9mmuZnRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "\n",
        "images.append(imagepath + 'hamburger/72111.jpg')\n",
        "images.append(imagepath + 'fried_rice/1391.jpg')\n",
        "images.append(imagepath + 'pizza/53217.jpg')\n",
        "\n",
        "predict_class(model, images)"
      ],
      "metadata": {
        "id": "GqLXSd6bFjVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting with random images\n",
        "images = []\n",
        "imagepath = main_path + 'images/'\n",
        "\n",
        "for i in range(3):\n",
        "  rdm_class = random.choice(classes)\n",
        "  images.append(imagepath+rdm_class+'/'+random.choice(os.listdir(imagepath+rdm_class)))\n",
        "\n",
        "predict_class(model, images)"
      ],
      "metadata": {
        "id": "bzm1yTsL9wRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(img_width, img_height))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  images = images / 255.\n",
        "  classes_pred = model.predict(images, batch_size=10)\n",
        "  index = np.argmax(classes_pred)\n",
        "  pred_value = labels[index]\n",
        "  print(fn)\n",
        "  print(classes_pred)\n",
        "\n",
        "  plt.imshow(img)                           \n",
        "  plt.axis('off')\n",
        "  plt.title(pred_value)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "NNV61BzbcupF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Export the Model"
      ],
      "metadata": {
        "id": "D9bBGApG1EtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the tf.saved_model API to save your model in the SavedModel format. \n",
        "export_dir = 'saved_model/1'"
      ],
      "metadata": {
        "id": "4P-ydm1IlWsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(model, export_dir)"
      ],
      "metadata": {
        "id": "3QtW3csMXQB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash -s $export_dir\n",
        "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"
      ],
      "metadata": {
        "id": "bo1K_ZTdTfWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded = tf.saved_model.load(export_dir)"
      ],
      "metadata": {
        "id": "vTtODzfP1Lox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(loaded.signatures.keys()))\n",
        "infer = loaded.signatures[\"serving_default\"]\n",
        "print(infer.structured_input_signature)\n",
        "print(infer.structured_outputs)"
      ],
      "metadata": {
        "id": "on5YKADL1O5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#save model to TFlite"
      ],
      "metadata": {
        "id": "ycGL5WOrXQ2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select mode of optimization\n",
        "mode = None\n",
        "\n",
        "if mode == 'Storage':\n",
        "    optimization = tf.lite.Optimize.OPTIMIZE_FOR_SIZE\n",
        "elif mode == 'Speed':\n",
        "    optimization = tf.lite.Optimize.OPTIMIZE_FOR_LATENCY\n",
        "else:\n",
        "    optimization = tf.lite.Optimize.DEFAULT"
      ],
      "metadata": {
        "id": "6tAy_Z64XfnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the TFLiteConverter SavedModel API to initialize the converter\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "\n",
        "# Set the optimzations\n",
        "converter.optimizations = [optimization]\n",
        "\n",
        "# Invoke the converter to finally generate the TFLite model\n",
        "tflite_model = converter.convert()\n",
        "tflite_model_file = 'converted_model.tflite'\n",
        "\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "Wk5PA0I1Xk0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the TFLite Model Using the Python Interpreter"
      ],
      "metadata": {
        "id": "NepMDkgU5hMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "with open(tflite_model_file, 'rb') as fid:\n",
        "    tflite_model = fid.read()\n",
        "    \n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]"
      ],
      "metadata": {
        "id": "qEgp5rth-9fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tflite(images):\n",
        "  for img_path in images:\n",
        "    img = image.load_img(img_path, target_size=(img_width, img_height))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    images = np.vstack([x])\n",
        "    images = images / 255.                             \n",
        "\n",
        "    interpreter.set_tensor(input_index, images)\n",
        "    interpreter.invoke()\n",
        "    pred = interpreter.get_tensor(output_index)\n",
        "\n",
        "    index = np.argmax(pred)\n",
        "    pred_value = labels[index]\n",
        "    print(pred)\n",
        "\n",
        "    plt.imshow(img)                           \n",
        "    plt.axis('off')\n",
        "    plt.title(pred_value)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XMwGyFXP6maT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "\n",
        "images.append(imagepath + 'hamburger/72111.jpg')\n",
        "images.append(imagepath + 'fried_rice/1391.jpg')\n",
        "images.append(imagepath + 'pizza/53217.jpg')\n",
        "\n",
        "predict_tflite(images)"
      ],
      "metadata": {
        "id": "2GblJCTYGa8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gather results for the randomly sampled test images\n",
        "images = []\n",
        "imagepath = main_path + 'images/'\n",
        "\n",
        "for i in range(3):\n",
        "  rdm_class = random.choice(classes)\n",
        "  images.append(imagepath+rdm_class+'/'+random.choice(os.listdir(imagepath+rdm_class)))\n",
        "\n",
        "predict_tflite(images)"
      ],
      "metadata": {
        "id": "nnwhvn1i29D8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download Save Model and TF Lite"
      ],
      "metadata": {
        "id": "Zd8W9bht7lCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r saved_model.zip saved_model"
      ],
      "metadata": {
        "id": "bjBtgpSy9S4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    files.download('converted_model.tflite')\n",
        "    files.download('saved_model.zip')\n",
        "    files.download(main_path+'meta/labels.txt')\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "iMm-GzCWJ2Jy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}